{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Work\\PlusW\\Lecture_5\n",
      "Moved file: books.csv\n",
      "Moved file: pubmed_articles.csv\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "csv_files = glob.glob(\"csv_files/*.csv\")\n",
    "for file in csv_files:\n",
    "    shutil.move(file, \"backup_folder/\")\n",
    "    print(f\"Moved file: {file}\")\n",
    "\n",
    "# Automating Export\n",
    "def export_data(df, filename, format):\n",
    "    if format == \"csv\":\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Data exported to {filename} in CSV format.\")\n",
    "    elif format == \"json\":\n",
    "        df.to_json(filename, orient=\"records\")\n",
    "        print(f\"Data exported to {filename} in JSON format.\")\n",
    "    else:\n",
    "        print(\"Unsupported format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to output.csv in CSV format.\n",
      "Data exported to output.json in JSON format.\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "# Creating a sample dataframe\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "'Age': [25, 30, 35],\n",
    "'City': ['New York', 'Los Angeles', 'Chicago']}\n",
    "df = pd.DataFrame(data)\n",
    "# Exporting to CSV\n",
    "export_data(df, \"output.csv\", \"csv\")\n",
    "# Exporting to JSON\n",
    "export_data(df, \"output.json\", \"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.54-py2.py3-none-any.whl (108 kB)\n",
      "     ---------------------------------------- 0.0/108.7 kB ? eta -:--:--\n",
      "     ----------- --------------------------- 30.7/108.7 kB 1.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 92.2/108.7 kB 1.1 MB/s eta 0:00:01\n",
      "     --------------------------------- -- 102.4/108.7 kB 837.8 kB/s eta 0:00:01\n",
      "     ------------------------------------ 108.7/108.7 kB 787.7 kB/s eta 0:00:00\n",
      "Collecting frozendict>=2.3.4\n",
      "  Downloading frozendict-2.4.6-cp310-cp310-win_amd64.whl (37 kB)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\mrg18\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from yfinance) (4.3.6)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\mrg18\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from yfinance) (2025.1)\n",
      "Collecting requests>=2.31\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting beautifulsoup4>=4.11.1\n",
      "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "     ---------------------------------------- 0.0/186.0 kB ? eta -:--:--\n",
      "     ------------------- ------------------- 92.2/186.0 kB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  184.3/186.0 kB 2.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- 186.0/186.0 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting multitasking>=0.0.7\n",
      "  Downloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\mrg18\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from yfinance) (2.2.3)\n",
      "Collecting peewee>=3.16.2\n",
      "  Downloading peewee-3.17.9.tar.gz (3.0 MB)\n",
      "     ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.1/3.0 MB 1.6 MB/s eta 0:00:02\n",
      "      --------------------------------------- 0.1/3.0 MB 1.6 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 0.2/3.0 MB 1.3 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 0.2/3.0 MB 1.4 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 0.3/3.0 MB 1.5 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 0.5/3.0 MB 1.7 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 0.6/3.0 MB 1.8 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 0.6/3.0 MB 1.7 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 0.7/3.0 MB 1.8 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 0.9/3.0 MB 2.0 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 0.9/3.0 MB 1.9 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 1.0/3.0 MB 1.9 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 1.1/3.0 MB 2.1 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 1.2/3.0 MB 1.9 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 1.3/3.0 MB 2.0 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 1.3/3.0 MB 2.0 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 1.4/3.0 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 1.5/3.0 MB 1.9 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 1.7/3.0 MB 1.9 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 1.8/3.0 MB 2.0 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 1.9/3.0 MB 2.0 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 2.0/3.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 2.3/3.0 MB 2.2 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 2.4/3.0 MB 2.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 2.6/3.0 MB 2.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 2.7/3.0 MB 2.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 2.9/3.0 MB 2.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.0/3.0 MB 2.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.0/3.0 MB 2.4 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\mrg18\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from yfinance) (2.2.3)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\mrg18\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mrg18\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mrg18\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=1.3.0->yfinance) (2025.1)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)\n",
      "     ---------------------------------------- 0.0/102.8 kB ? eta -:--:--\n",
      "     -------------------------------------  102.4/102.8 kB 5.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- 102.8/102.8 kB 2.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mrg18\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "Building wheels for collected packages: peewee\n",
      "  Building wheel for peewee (pyproject.toml): started\n",
      "  Building wheel for peewee (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for peewee: filename=peewee-3.17.9-py3-none-any.whl size=139127 sha256=602f63f8e9314fdea37d1ae24717cb67fdbbdac624473b1ff0287bb225992afa\n",
      "  Stored in directory: c:\\users\\mrg18\\appdata\\local\\pip\\cache\\wheels\\fd\\fd\\5e\\90b9ec95da4fd6c96237b580ce74f89d6bdea547ad151ab5f4\n",
      "Successfully built peewee\n",
      "Installing collected packages: peewee, multitasking, urllib3, soupsieve, idna, frozendict, charset-normalizer, certifi, requests, beautifulsoup4, yfinance\n",
      "Successfully installed beautifulsoup4-4.13.3 certifi-2025.1.31 charset-normalizer-3.4.1 frozendict-2.4.6 idna-3.10 multitasking-0.0.11 peewee-3.17.9 requests-2.32.3 soupsieve-2.6 urllib3-2.3.0 yfinance-0.2.54\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\mrg18\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install yfinance\n",
    "import yfinance as yf\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored data for NVDA\n",
      "Stored data for NVDA\n",
      "Stored data for NVDA\n",
      "Stored data for NVDA\n",
      "Stored data for NVDA\n",
      "   id symbol            timestamp        open        high         low  \\\n",
      "0  10   NVDA  2025-03-20 21:40:15  118.419998  118.529999  118.309998   \n",
      "1   9   NVDA  2025-03-20 21:39:14  118.419998  118.529999  118.309998   \n",
      "2   8   NVDA  2025-03-20 21:38:14  118.419998  118.529999  118.309998   \n",
      "3   7   NVDA  2025-03-20 21:37:14  118.419998  118.529999  118.309998   \n",
      "4   6   NVDA  2025-03-20 21:36:13  118.419998  118.529999  118.309998   \n",
      "\n",
      "        close   volume  \n",
      "0  118.470001  3024760  \n",
      "1  118.470001  3024760  \n",
      "2  118.470001  3024760  \n",
      "3  118.470001  3024760  \n",
      "4  118.470001  3024760  \n"
     ]
    }
   ],
   "source": [
    "# Database setup\n",
    "db_name = \"stocks.db\"\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS stock_data (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                symbol TEXT,\n",
    "                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "                open REAL,\n",
    "                high REAL,\n",
    "                low REAL,\n",
    "                close REAL,\n",
    "                volume INTEGER)''')\n",
    "conn.commit()\n",
    "\n",
    "# Function to fetch stock data\n",
    "\n",
    "def fetch_stock_data(symbol):\n",
    "    try:\n",
    "        stock = yf.Ticker(symbol)\n",
    "        data = stock.history(period=\"1d\", interval=\"1m\")\n",
    "        if data.empty:\n",
    "            print(f\"No data found for {symbol}. Skipping...\")\n",
    "            return None # Return None if no data is available\n",
    "        latest = data.iloc[-1] # Get the most recent price data\n",
    "        return {\n",
    "        \"symbol\": symbol,\n",
    "        \"open\": latest[\"Open\"],\n",
    "        \"high\": latest[\"High\"],\n",
    "        \"low\": latest[\"Low\"],\n",
    "        \"close\": latest[\"Close\"],\n",
    "        \"volume\": latest[\"Volume\"]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {symbol}: {e}\")\n",
    "        return None\n",
    "    \n",
    "# Function to store data in SQLite\n",
    "\n",
    "def store_data(symbol):\n",
    "    stock_data = fetch_stock_data(symbol)\n",
    "    if stock_data: # Only store if data is available\n",
    "        cursor.execute('''INSERT INTO stock_data (symbol, open, high, low,\n",
    "                        close, volume)\n",
    "                        VALUES (?, ?, ?, ?, ?, ?)''',\n",
    "\n",
    "    (stock_data[\"symbol\"], stock_data[\"open\"],\n",
    "    stock_data[\"high\"],\n",
    "    stock_data[\"low\"], stock_data[\"close\"],\n",
    "    stock_data[\"volume\"]))\n",
    "    conn.commit()\n",
    "    print(f\"Stored data for {symbol}\")\n",
    "    \n",
    "# Function to analyze stock data\n",
    "def analyze_stock(symbol):\n",
    "    df = pd.read_sql_query(\"SELECT * FROM stock_data WHERE symbol=? ORDER BY \"\n",
    "    \"timestamp DESC LIMIT 100\", conn, params=(symbol,))\n",
    "    print(df)\n",
    "\n",
    "# Example Usage\n",
    "symbol = \"NVDA\" # NVIDIA\n",
    "for _ in range(5): # Fetch data 5 times with intervals\n",
    "    store_data(symbol)\n",
    "    time.sleep(60) # Wait for 1 minute before fetching again\n",
    "\n",
    "analyze_stock(symbol)\n",
    "# Close database connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to pubmed_articles.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "BASE_URL = \"https://pubmed.ncbi.nlm.nih.gov/\"\n",
    "search_query = \"genomics\"\n",
    "num_pages = 1\n",
    "\n",
    "def get_pubmed_articles(query, pages):\n",
    "    articles_list = []\n",
    "    for page in range(1, pages + 1):\n",
    "        url = f\"{BASE_URL}?term={query}&page={page}\"\n",
    "        response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        articles = soup.find_all(\"article\", class_=\"full-docsum\")\n",
    "        for article in articles:\n",
    "            title_tag = article.find(\"a\", class_=\"docsum-title\")\n",
    "            title = title_tag.get_text(strip=True) if title_tag else \"No title\"\n",
    "            \n",
    "            summary_tag = article.find(\"div\", class_=\"full-view-snippet\")\n",
    "            summary = summary_tag.get_text(strip=True) if summary_tag else \"No summary\"\n",
    "            \n",
    "            articles_list.append({\"Title\": title, \"Summary\": summary})\n",
    "    \n",
    "    return articles_list\n",
    "\n",
    "articles_data = get_pubmed_articles(search_query, num_pages)\n",
    "df = pd.DataFrame(articles_data)\n",
    "df.to_csv(\"pubmed_articles.csv\", index=False)\n",
    "print(\"Data saved to pubmed_articles.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
